// scripts/cleanup-queue.ts
// Clean up old/completed/failed jobs from the queue

// Load .env.local file FIRST (before any imports that need env vars)
import { config } from 'dotenv';
import { resolve } from 'path';

// Load .env.local file
const envPath = resolve(process.cwd(), '.env.local');
const result = config({ path: envPath });

if (result.error) {
  console.warn('‚ö†Ô∏è  Could not load .env.local:', result.error.message);
  console.warn('   Using system environment variables instead');
} else {
  console.log('‚úÖ Loaded .env.local file');
  if (process.env.UPSTASH_REDIS_URL) {
    console.log('   Redis URL found:', process.env.UPSTASH_REDIS_URL.substring(0, 30) + '...');
  }
}

// Verify environment variable is loaded
if (!process.env.UPSTASH_REDIS_URL && !process.env.REDIS_URL) {
  console.error('‚ùå ERROR: UPSTASH_REDIS_URL or REDIS_URL not found in environment!');
  console.error('   Make sure .env.local file exists and contains UPSTASH_REDIS_URL');
  process.exit(1);
}

async function cleanupQueue() {
  try {
    // Dynamic import AFTER environment variables are loaded
    const { sagaQueue } = await import('../src/lib/queue/saga-queue');
    
    console.log('üßπ Cleaning up queue...');
    
    // Get all jobs from different states
    const waitingJobs = await sagaQueue.getJobs(['waiting']);
    const activeJobs = await sagaQueue.getJobs(['active']);
    const completedJobs = await sagaQueue.getJobs(['completed']);
    const failedJobs = await sagaQueue.getJobs(['failed']);
    const delayedJobs = await sagaQueue.getJobs(['delayed']);
    
    const allJobs = [...waitingJobs, ...activeJobs, ...completedJobs, ...failedJobs, ...delayedJobs];
    
    console.log(`üìä Found ${allJobs.length} jobs in queue`);
    
    // Group by status
    const byStatus = {
      waiting: waitingJobs,
      active: activeJobs,
      completed: completedJobs,
      failed: failedJobs,
      delayed: delayedJobs
    };
    
    console.log('\nüìà Job status breakdown:');
    console.log(`  Waiting: ${byStatus.waiting.length}`);
    console.log(`  Active: ${byStatus.active.length}`);
    console.log(`  Completed: ${byStatus.completed.length}`);
    console.log(`  Failed: ${byStatus.failed.length}`);
    console.log(`  Delayed: ${byStatus.delayed.length}`);
    
    // Show waiting jobs before cleanup
    if (byStatus.waiting.length > 0) {
      console.log('\n‚è≥ Waiting jobs (will be removed):');
      for (const job of byStatus.waiting.slice(0, 10)) {
        const sagaId = job.data?.sagaId || 'unknown';
        const gameId = job.data?.gameId || 'unknown';
        const isUUID = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i.test(sagaId);
        console.log(`  - Job ${job.id}: ${sagaId} (game ${gameId}) ${isUUID ? '‚úÖ' : '‚ö†Ô∏è old format'}`);
      }
      if (byStatus.waiting.length > 10) {
        console.log(`  ... and ${byStatus.waiting.length - 10} more`);
      }
    }
    
    let removedCount = 0;
    
    // Remove ALL waiting jobs (eski job'lar genelde waiting'de)
    console.log('\nüóëÔ∏è  Removing waiting jobs...');
    for (const job of byStatus.waiting) {
      try {
        await job.remove();
        removedCount++;
      } catch (err: any) {
        console.warn(`  ‚ö†Ô∏è  Failed to remove job ${job.id}: ${err.message}`);
      }
    }
    
    // Remove ALL completed jobs
    console.log('üóëÔ∏è  Removing completed jobs...');
    for (const job of byStatus.completed) {
      try {
        await job.remove();
        removedCount++;
      } catch (err: any) {
        console.warn(`  ‚ö†Ô∏è  Failed to remove job ${job.id}: ${err.message}`);
      }
    }
    
    // Remove ALL failed jobs
    console.log('üóëÔ∏è  Removing failed jobs...');
    for (const job of byStatus.failed) {
      try {
        await job.remove();
        removedCount++;
      } catch (err: any) {
        console.warn(`  ‚ö†Ô∏è  Failed to remove job ${job.id}: ${err.message}`);
      }
    }
    
    // Remove ALL delayed jobs
    console.log('üóëÔ∏è  Removing delayed jobs...');
    for (const job of byStatus.delayed) {
      try {
        await job.remove();
        removedCount++;
      } catch (err: any) {
        console.warn(`  ‚ö†Ô∏è  Failed to remove job ${job.id}: ${err.message}`);
      }
    }
    
    // Active jobs'larƒ± da temizle (muhtemelen takƒ±lƒ± kalmƒ±≈ü)
    if (byStatus.active.length > 0) {
      console.log(`\nüóëÔ∏è  Removing ${byStatus.active.length} active jobs (may be stuck)...`);
      for (const job of byStatus.active) {
        try {
          // Active job'u √∂nce fail et, sonra remove et
          try {
            await job.moveToFailed(new Error('Manually removed - stuck job'), '0');
            console.log(`  ‚ö†Ô∏è  Moved active job to failed: ${job.id}`);
          } catch (err: any) {
            console.warn(`  ‚ö†Ô∏è  Could not move job to failed: ${err.message}`);
          }
          await job.remove();
          removedCount++;
          console.log(`  ‚úÖ Removed active job: ${job.id}`);
        } catch (err: any) {
          console.warn(`  ‚ö†Ô∏è  Failed to remove active job ${job.id}: ${err.message}`);
        }
      }
    }
    
    console.log(`\n‚úÖ Successfully removed ${removedCount} jobs`);
    console.log(`üìä Remaining active jobs: ${byStatus.active.length}`);
    
    // Clean up the queue (remove old data)
    // Force obliterate to remove locked jobs
    try {
      if (byStatus.active.length > 0) {
        console.log('\nüîì Force cleaning queue to remove locked jobs...');
        await sagaQueue.obliterate({ force: true });
        console.log('‚úÖ Queue force cleaned successfully (locked jobs removed)');
      } else {
        await sagaQueue.obliterate({ force: false });
        console.log('‚úÖ Queue cleaned successfully');
      }
    } catch (err: any) {
      console.warn('‚ö†Ô∏è  Could not obliterate queue:', err.message);
    }
    
    process.exit(0);
  } catch (error: any) {
    console.error('‚ùå Cleanup failed:', error.message);
    console.error(error.stack);
    process.exit(1);
  }
}

cleanupQueue();

